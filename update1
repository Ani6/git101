# -*- coding: utf-8 -*-
"""
Created on Fri Nov  2 05:00:22 2018

@author: Aniruddha
"""

import pandas as pd
import numpy as np
import matplotlib

# save filepath to variable for easier access
train_file_path = 'train.csv'
# read the data and store data in DataFrame titled data
data_pd = pd.read_csv('train.csv') 
data = np.array(data_pd) #.values

features = data[:,0:24]
targets = data[:,-1]

day_ref = ["sunday",
           "monday",
           "tuesday",
           "wednesday",
           "thursday",
           "friday",
           "saturday"
           ]
def sigmoid(z):
  return 1 / (1 + math.exp(-z))

for idx, day in enumerate(day_ref):
    day_hot = [int(i==day_ref[idx]) for i in features[:,23]]
    day_hot = np.expand_dims(np.array(day_hot),axis=1)
    features = np.append(features, day_hot, axis=1)

for idx, day in enumerate(day_ref):
    day_hot = [int(i==day_ref[idx]) for i in features[:,24]]
    day_hot = np.expand_dims(np.array(day_hot),axis=1)
    features = np.append(features, day_hot, axis=1)
    
features = np.concatenate((features[:,:22], features[:,44:]),axis=1)
#features = np.delete(features, features[:,22], axis=1)

train_data = features[0:22399,:]
val_data = features[22400:,:]
train_targets = targets[0:22399]
val_targets = targets[22400:]


#Variable initialization
epoch=5000 #Setting training iterations
lr=0.001 #Setting learning rate
inputlayer_neurons = 36 #number of features in data set
hiddenlayer_neurons = 100 #number of hidden layers neurons
output_neurons = 3 #number of neurons at output layer

#weight and bias initialization
wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))
bh=np.random.uniform(size=(1,hiddenlayer_neurons))
wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))
bout=np.random.uniform(size=(1,output_neurons))

for i in range(epoch):
    
    #Forward Propagation
    x = features[i]
    hidden_layer_input1=np.dot(x,wh)
    hidden_layer_input=hidden_layer_input1 + bh
    hiddenlayer_activations = sigmoid(hidden_layer_input)
    output_layer_input1=np.dot(hiddenlayer_activations,wout)
    output_layer_input= output_layer_input1+ bout
    output = sigmoid(output_layer_input)
    
    #Backpropagation
    E = y-output
    slope_output_layer = derivatives_sigmoid(output)
    slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)
    d_output = E * slope_output_layer
    Error_at_hidden_layer = d_output.dot(wout.T)
    d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer
    wout += hiddenlayer_activations.T.dot(d_output) *lr
    bout += np.sum(d_output, axis=0,keepdims=True) *lr
    wh += X.T.dot(d_hiddenlayer) *lr
    bh += np.sum(d_hiddenlayer, axis=0,keepdims=True) *lr

print (output)
